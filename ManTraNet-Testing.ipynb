{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "literary-royalty",
   "metadata": {},
   "source": [
    "# check gpu resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "sought-packaging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 26 03:19:08 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.39       Driver Version: 460.39       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:19:00.0 Off |                  N/A |\n",
      "| 63%   83C    P2   201W / 250W |  10890MiB / 11019MiB |     84%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:1A:00.0 Off |                  N/A |\n",
      "| 67%   83C    P2   197W / 250W |  10890MiB / 11019MiB |     86%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:67:00.0 Off |                  N/A |\n",
      "| 72%   85C    P2   220W / 250W |  10890MiB / 11019MiB |     86%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  Off  | 00000000:68:00.0 Off |                  N/A |\n",
      "| 69%   84C    P2   161W / 250W |  10889MiB / 11016MiB |     85%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# gpu resources\n",
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-transcript",
   "metadata": {},
   "source": [
    "# testing ManTraNet on different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "laughing-settle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hearing-breeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ManTraNet paths\n",
    "manTraNet_root = './'\n",
    "manTraNet_srcDir = os.path.join( manTraNet_root, 'src' )\n",
    "sys.path.insert( 0, manTraNet_srcDir )\n",
    "manTraNet_modelDir = os.path.join( manTraNet_root, 'pretrained_weights' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-recovery",
   "metadata": {},
   "source": [
    "# setup dataset paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "figured-alexandria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/samplePairs.csv\n",
      "INFO: in total, load 72 samples\n"
     ]
    }
   ],
   "source": [
    "# sample ManTraNet datasets included in repo\n",
    "manTraNet_dataDir = os.path.join( manTraNet_root, 'data' )\n",
    "sample_file = os.path.join( manTraNet_dataDir, 'samplePairs.csv' )\n",
    "print(sample_file)\n",
    "assert os.path.isfile( sample_file ), \"ERROR: can NOT find sample data, check `manTraNet_root`\"\n",
    "with open( sample_file ) as IN :\n",
    "    sample_pairs = [line.strip().split(',') for line in IN.readlines() ]\n",
    "L = len(sample_pairs)\n",
    "print(\"INFO: in total, load\", L, \"samples\")\n",
    "    \n",
    "def get_a_random_pair() :\n",
    "    idx = np.random.randint(0,L)\n",
    "    return ( os.path.join( manTraNet_dataDir, this ) for this in sample_pairs[idx] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "smaller-mining",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CG-1050 dataset\n",
    "mfc_data = os.path.join(manTraNet_root, 'openmfc_data')\n",
    "cg_1050 = os.path.join(mfc_data, 'CG_1050')\n",
    "cg_1050_description = os.path.join(cg_1050, 'DESCRIPTION')\n",
    "\n",
    "cg_1050_mask = os.path.join(cg_1050, 'MASK')\n",
    "cg_1050_original = os.path.join(cg_1050, 'ORIGINAL')\n",
    "cg_1050_tampered = os.path.join(cg_1050, 'TAMPERED')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-explanation",
   "metadata": {},
   "source": [
    "# load dataset description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "demographic-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "description_path = os.path.join(cg_1050_description, 'Dataset_description_v2.csv')\n",
    "\n",
    "df = pd.read_csv(description_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "right-album",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PHOTO NAME (Original)</th>\n",
       "      <th>IMAGE DESCRIPTION</th>\n",
       "      <th>PHOTO PLACE</th>\n",
       "      <th>FOLDER NAME</th>\n",
       "      <th>TAMPERING TYPE</th>\n",
       "      <th>PHOTO NAME (Tampered)</th>\n",
       "      <th>OBJECT</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>FOLDER NAME.1</th>\n",
       "      <th>PHOTO NAME (Mask)</th>\n",
       "      <th>Pixel changed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Im_1</td>\n",
       "      <td>Color 3456x4608</td>\n",
       "      <td>Classroom</td>\n",
       "      <td>T_1</td>\n",
       "      <td>Copy-move</td>\n",
       "      <td>Im1_cm1.jpg</td>\n",
       "      <td>telecomunication tower</td>\n",
       "      <td>Middle left</td>\n",
       "      <td>Mask1</td>\n",
       "      <td>Mask1_cm1.png</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Im_1</td>\n",
       "      <td>Color 3456x4608</td>\n",
       "      <td>Classroom</td>\n",
       "      <td>T_1</td>\n",
       "      <td>Copy-move</td>\n",
       "      <td>Im1_cm2.jpg</td>\n",
       "      <td>Window</td>\n",
       "      <td>Middle left</td>\n",
       "      <td>Mask1</td>\n",
       "      <td>Mask1_cm2.png</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Im_1</td>\n",
       "      <td>Color 3456x4608</td>\n",
       "      <td>Classroom</td>\n",
       "      <td>T_1</td>\n",
       "      <td>Copy-move</td>\n",
       "      <td>Im1_cm3.jpg</td>\n",
       "      <td>Tank</td>\n",
       "      <td>Middle left</td>\n",
       "      <td>Mask1</td>\n",
       "      <td>Mask1_cm3.png</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Im_1</td>\n",
       "      <td>Color 3456x4608</td>\n",
       "      <td>Classroom</td>\n",
       "      <td>T_1</td>\n",
       "      <td>Copy-move</td>\n",
       "      <td>Im1_cm4.jpg</td>\n",
       "      <td>Floor</td>\n",
       "      <td>Upper left</td>\n",
       "      <td>Mask1</td>\n",
       "      <td>Mask1_cm4.png</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Im_1</td>\n",
       "      <td>Color 3456x4608</td>\n",
       "      <td>Classroom</td>\n",
       "      <td>T_1</td>\n",
       "      <td>Cut-paste</td>\n",
       "      <td>Im1_cmfr1.jpg</td>\n",
       "      <td>Church tower</td>\n",
       "      <td>Middle left</td>\n",
       "      <td>Mask1</td>\n",
       "      <td>Mask1_cmfr1.png</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 PHOTO NAME (Original) IMAGE DESCRIPTION PHOTO PLACE FOLDER NAME  \\\n",
       "0           0                  Im_1   Color 3456x4608   Classroom         T_1   \n",
       "1           1                  Im_1   Color 3456x4608   Classroom         T_1   \n",
       "2           2                  Im_1   Color 3456x4608   Classroom         T_1   \n",
       "3           3                  Im_1   Color 3456x4608   Classroom         T_1   \n",
       "4           4                  Im_1   Color 3456x4608   Classroom         T_1   \n",
       "\n",
       "  TAMPERING TYPE PHOTO NAME (Tampered)                  OBJECT     LOCATION  \\\n",
       "0      Copy-move           Im1_cm1.jpg  telecomunication tower  Middle left   \n",
       "1      Copy-move           Im1_cm2.jpg                  Window  Middle left   \n",
       "2      Copy-move           Im1_cm3.jpg                    Tank  Middle left   \n",
       "3      Copy-move           Im1_cm4.jpg                   Floor   Upper left   \n",
       "4      Cut-paste         Im1_cmfr1.jpg            Church tower  Middle left   \n",
       "\n",
       "  FOLDER NAME.1 PHOTO NAME (Mask) Pixel changed  \n",
       "0         Mask1     Mask1_cm1.png         Black  \n",
       "1         Mask1     Mask1_cm2.png         Black  \n",
       "2         Mask1     Mask1_cm3.png         Black  \n",
       "3         Mask1     Mask1_cm4.png         Black  \n",
       "4         Mask1   Mask1_cmfr1.png         Black  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-worry",
   "metadata": {},
   "source": [
    "# build dataset list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dimensional-geometry",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tamper_path\"] = df[\"FOLDER NAME\"] + '/' + df[\"PHOTO NAME (Tampered)\"]\n",
    "df[\"mask_path\"] = df[\"FOLDER NAME.1\"] + '/' + df[\"PHOTO NAME (Mask)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "protecting-bacteria",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sample:\n",
    "    def __init__(self, name, tampered, masks):\n",
    "        self.name = name\n",
    "        self.tampered = tampered\n",
    "        self.masks = masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "established-target",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = []\n",
    "unique_images = list(df['PHOTO NAME (Original)'].unique())\n",
    "\n",
    "for image in unique_images:\n",
    "    tampered = list(df.loc[df['PHOTO NAME (Original)'] == image]['tamper_path'])\n",
    "    masks = list(df.loc[df['PHOTO NAME (Original)'] == image]['mask_path'])\n",
    "    sample = Sample(name=image,\n",
    "                   tampered=tampered,\n",
    "                   masks=masks)\n",
    "    dataset.append(sample)\n",
    "\n",
    "# dataset should have 100 original images (there are more tampered and masks)\n",
    "assert len(dataset) == 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "agricultural-authentication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im_1\n",
      "['T_1/Im1_cm1.jpg', 'T_1/Im1_cm2.jpg', 'T_1/Im1_cm3.jpg', 'T_1/Im1_cm4.jpg', 'T_1/Im1_cmfr1.jpg', 'T_1/Im1_col1.jpg', 'T_1/Im1_col2.jpg', 'T_1/Im1_col3.jpg', 'T_1/Im1_r1.jpg', 'T_1/Im1_r2.jpg', 'T_1/Im1_r3.jpg']\n",
      "['Mask1/Mask1_cm1.png', 'Mask1/Mask1_cm2.png', 'Mask1/Mask1_cm3.png', 'Mask1/Mask1_cm4.png', 'Mask1/Mask1_cmfr1.png', 'Mask1/Mask1_col1.png', 'Mask1/Mask1_col2.png', 'Mask1/Mask1_col3.png', 'Mask1/Mask1_r1.png', 'Mask1/Mask1_r2.png', 'Mask1/Mask1_r3.png']\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0].name)\n",
    "print(dataset[0].tampered)\n",
    "print(dataset[0].masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "respiratory-divide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset[0].tampered))\n",
    "print(len(dataset[0].masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "secure-judges",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_random_sample():\n",
    "    idx = np.random.randint(0,len(dataset))\n",
    "    sample = dataset[idx]\n",
    "    original_path = os.path.join(cg_1050_original, sample.name + '.jpg')\n",
    "    idx_mt = np.random.randint(0,len(sample.tampered)) # each tampered image has a mask, so lengths are the same\n",
    "    mask_path = os.path.join(cg_1050_mask, sample.masks[idx_mt])\n",
    "    tampered_path = os.path.join(cg_1050_tampered, sample.tampered[idx_mt])\n",
    "    return (original_path, mask_path, tampered_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-royal",
   "metadata": {},
   "source": [
    "# Load A Pretrained ManTraNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "amino-paradise",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: use activation in the last CONV=None\n",
      "INFO: unfreeze feature extraction part, trainable=True\n"
     ]
    }
   ],
   "source": [
    "import modelCore\n",
    "manTraNet = modelCore.load_pretrain_model_by_index( 4, manTraNet_modelDir )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "casual-slide",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________\n",
      "Layer (type)                           Output Shape               Param #       Connected to                            \n",
      "========================================================================================================================\n",
      "img_in (InputLayer)                    (None, None, None, 3)      0                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "Featex (Model)                         (None, None, None, 256)    3675181       img_in[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "outlierTrans (Conv2D)                  (None, None, None, 64)     16384         Featex[1][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "bnorm (BatchNormalization)             (None, None, None, 64)     128           outlierTrans[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "glbStd (GlobalStd2D)                   (None, 1, 1, 64)           64            bnorm[0][0]                             \n",
      "________________________________________________________________________________________________________________________\n",
      "nestedAvgFeatex (NestedWindowAverageFe (None, 4, None, None, 64)  0             bnorm[0][0]                             \n",
      "________________________________________________________________________________________________________________________\n",
      "expTime (Lambda)                       (None, 1, 1, 1, 64)        0             glbStd[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "divStd (Lambda)                        (None, 4, None, None, 64)  0             nestedAvgFeatex[0][0]                   \n",
      "                                                                                expTime[0][0]                           \n",
      "________________________________________________________________________________________________________________________\n",
      "cLSTM (ConvLSTM2D)                     (None, None, None, 8)      112928        divStd[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "pred (Conv2D)                          (None, None, None, 1)      393           cLSTM[0][0]                             \n",
      "========================================================================================================================\n",
      "Total params: 3,805,078\n",
      "Trainable params: 3,804,950\n",
      "Non-trainable params: 128\n",
      "________________________________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# ManTraNet Architecture \n",
    "print(manTraNet.summary(line_length=120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "subject-horizon",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________\n",
      "Layer (type)                                          Output Shape                                    Param #           \n",
      "========================================================================================================================\n",
      "image_in (InputLayer)                                 (None, None, None, 3)                           0                 \n",
      "________________________________________________________________________________________________________________________\n",
      "b1c1 (CombinedConv2D)                                 (None, None, None, 16)                          525               \n",
      "________________________________________________________________________________________________________________________\n",
      "b1c2 (Conv2DSymPadding)                               (None, None, None, 32)                          4640              \n",
      "________________________________________________________________________________________________________________________\n",
      "b2c1 (Conv2DSymPadding)                               (None, None, None, 64)                          18496             \n",
      "________________________________________________________________________________________________________________________\n",
      "b2c2 (Conv2DSymPadding)                               (None, None, None, 64)                          36928             \n",
      "________________________________________________________________________________________________________________________\n",
      "b3c1 (Conv2DSymPadding)                               (None, None, None, 128)                         73856             \n",
      "________________________________________________________________________________________________________________________\n",
      "b3c2 (Conv2DSymPadding)                               (None, None, None, 128)                         147584            \n",
      "________________________________________________________________________________________________________________________\n",
      "b3c3 (Conv2DSymPadding)                               (None, None, None, 128)                         147584            \n",
      "________________________________________________________________________________________________________________________\n",
      "b4c1 (Conv2DSymPadding)                               (None, None, None, 256)                         295168            \n",
      "________________________________________________________________________________________________________________________\n",
      "b4c2 (Conv2DSymPadding)                               (None, None, None, 256)                         590080            \n",
      "________________________________________________________________________________________________________________________\n",
      "b4c3 (Conv2DSymPadding)                               (None, None, None, 256)                         590080            \n",
      "________________________________________________________________________________________________________________________\n",
      "b5c1 (Conv2DSymPadding)                               (None, None, None, 256)                         590080            \n",
      "________________________________________________________________________________________________________________________\n",
      "b5c2 (Conv2DSymPadding)                               (None, None, None, 256)                         590080            \n",
      "________________________________________________________________________________________________________________________\n",
      "transform (Conv2DSymPadding)                          (None, None, None, 256)                         590080            \n",
      "________________________________________________________________________________________________________________________\n",
      "L2 (Lambda)                                           (None, None, None, 256)                         0                 \n",
      "========================================================================================================================\n",
      "Total params: 3,675,181\n",
      "Trainable params: 3,675,181\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Image Manipulation Classification Network\n",
    "IMCFeatex = manTraNet.get_layer('Featex')\n",
    "print(IMCFeatex.summary(line_length=120))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-tampa",
   "metadata": {},
   "source": [
    "# test samples from cg-1050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "irish-leonard",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "def read_rgb_image( image_file ) :\n",
    "    rgb = cv2.imread( image_file, 1 )[...,::-1]\n",
    "    return rgb\n",
    "    \n",
    "def decode_an_image_array( rgb, manTraNet ) :\n",
    "    x = np.expand_dims( rgb.astype('float32')/255.*2-1, axis=0 )\n",
    "    t0 = datetime.now()\n",
    "    y = manTraNet.predict(x)[0,...,0]\n",
    "    t1 = datetime.now()\n",
    "    return y, t1-t0\n",
    "\n",
    "def decode_an_image_file( image_file, manTraNet ) :\n",
    "    rgb = read_rgb_image( image_file )\n",
    "    mask, ptime = decode_an_image_array( rgb, manTraNet )\n",
    "    return rgb, mask, ptime.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "tutorial-montgomery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./openmfc_data/CG_1050/ORIGINAL/Im_39.jpg\n",
      "./openmfc_data/CG_1050/MASK/Mask39/Mask39_col1.png\n",
      "./openmfc_data/CG_1050/TAMPERED/T_39/Im39_col1.jpg\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for k in range(8) :\n",
    "    # get a sample\n",
    "    #forged_file, original_file = get_a_random_pair()\n",
    "    orig_file, mask_file, tampered_file = get_a_random_sample()\n",
    "    print(orig_file)\n",
    "    print(mask_file)\n",
    "    print(tampered_file)\n",
    "    print(os.path.exists(orig_file))\n",
    "    print(os.path.exists(mask_file))\n",
    "    print(os.path.exists(tampered_file))\n",
    "    break\n",
    "    \n",
    "    # load the original image just for reference\n",
    "    ori = read_rgb_image( original_file )\n",
    "    # manipulation detection using ManTraNet\n",
    "    rgb, mask, ptime = decode_an_image_file( forged_file, manTraNet ) \n",
    "    # show results\n",
    "    pyplot.figure( figsize=(15,5) )\n",
    "    pyplot.subplot(131)\n",
    "    pyplot.imshow( ori )\n",
    "    pyplot.title('Original Image')\n",
    "    pyplot.subplot(132)\n",
    "    pyplot.imshow( rgb )\n",
    "    pyplot.title('Forged Image (ManTra-Net Input)')\n",
    "    pyplot.subplot(133)\n",
    "    pyplot.imshow( mask, cmap='gray' )\n",
    "    pyplot.title('Predicted Mask (ManTra-Net Output)')\n",
    "    pyplot.suptitle('Decoded {} of size {} for {:.2f} seconds'.format( os.path.basename( forged_file ), rgb.shape, ptime ) )\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-nirvana",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
